{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des Fichiers CSV traités avec l'analyse de sentiment\n",
    "Ce notebook récupère les fichiers traités sur la machine distante et permet de les lire, \n",
    "les labélliser et les concaténer entre eux. \n",
    "A la fin, le fichier all.csv est le fichier contenant toute mon analyse de sentiment en termes de polarité, avec l'attribution d'un sentiment pour chaque tweet. Ce fichier va nous permettre de pousuivre l'analyse de la polarité pour une eventuelle représentation graphique des groupes de sentiments (T-SNE Minst); et une analyse des émotions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on récup les fichiers traités \n",
    "file_paths = [\n",
    "    r\"C:\\Users\\alyas\\Desktop\\TER\\test_sentiment_analysis\\tweets_cancer_fasting_all.csv\",\n",
    "    r\"C:\\Users\\alyas\\Desktop\\TER\\test_sentiment_analysis\\tweets_cancer_sport_all.csv\", \n",
    "    r'C:\\\\Users\\\\alyas\\\\Desktop\\\\TER\\\\test_sentiment_analysis\\\\tweets_cancer_cannabis_all.csv'\n",
    "]\n",
    "\n",
    "dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alyas\\Desktop\\TER\\test_sentiment_analysis\\tweets_cancer_fasting_all.csv 1035\n",
      "C:\\Users\\alyas\\Desktop\\TER\\test_sentiment_analysis\\tweets_cancer_sport_all.csv 591\n",
      "C:\\\\Users\\\\alyas\\\\Desktop\\\\TER\\\\test_sentiment_analysis\\\\tweets_cancer_cannabis_all.csv 1118\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import io\n",
    "\n",
    "def preprocess_csv(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            cleaned_content = re.sub(r'[^\\x00-\\x7F]+', '', file.read())\n",
    "        df = pd.read_csv(io.StringIO(cleaned_content))\n",
    "        # Your data processing code here\n",
    "        df['Sentiment'] = df[['positive', 'neutral', 'negative']].idxmax(axis=1)\n",
    "        df['Sentiment'] = df['Sentiment'].map({'positive': 'pos', 'neutral': 'neutral', 'negative': 'neg'})\n",
    "        emotion_columns = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
    "        df['Emotion'] = df[emotion_columns].idxmax(axis=1)\n",
    "        df['Emotion'] = df['Emotion'].map({\n",
    "            'anger': 'angry',\n",
    "            'anticipation': 'anticipation',\n",
    "            'disgust': 'disgust',\n",
    "            'fear': 'fear',\n",
    "            'joy': 'joy',\n",
    "            'love': 'love',\n",
    "            'optimism': 'optimism',\n",
    "            'pessimism': 'pessimism',\n",
    "            'sadness': 'sadness',\n",
    "            'surprise': 'surprise',\n",
    "            'trust': 'trust'\n",
    "        })\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# List of file paths\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\alyas\\Desktop\\TER\\test_sentiment_analysis\\tweets_cancer_fasting_all.csv\",\n",
    "    r\"C:\\Users\\alyas\\Desktop\\TER\\test_sentiment_analysis\\tweets_cancer_sport_all.csv\",\n",
    "    r\"C:\\\\Users\\\\alyas\\\\Desktop\\\\TER\\\\test_sentiment_analysis\\\\tweets_cancer_cannabis_all.csv\"  # Add the cannabis file here\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df = preprocess_csv(file_path)\n",
    "    if df is not None:\n",
    "        dfs.append(df)\n",
    "        print(file_path, len(df))\n",
    "\n",
    "# Now dfs contains the processed DataFrames for all the CSV files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       id                                               Text  \\\n",
      "0     1370044456842493954  Do fasting mimicking diets during chemotherapy...   \n",
      "1      794281747043250176  #fasting may improve #cancer #treatment but ne...   \n",
      "2     1148806240010588161  Take notes.\\n\\nOrder your seamoss and receive ...   \n",
      "3      643251385035657216  If you've ever been affected by #cancer #MUSTR...   \n",
      "4     1295469082221981696   The latest The STEM Daily! http #fasting #cancer   \n",
      "...                   ...                                                ...   \n",
      "2739    91659659072647168  Cured: A Cannabis Story (A film by David Tripl...   \n",
      "2740    98751766488813568  #Cannabis healing, the truth: http \"the govern...   \n",
      "2741   194423800673206272  Medical #marijuana bill passes committee - #Ca...   \n",
      "2742   197566368059637761  http If you have medical condition being treat...   \n",
      "2743   162632942022172673  Yo Christie! Don't be like Corzine! http #cann...   \n",
      "\n",
      "      positive  neutral  negative     anger  anticipation   disgust      fear  \\\n",
      "0       0.0687   0.9167    0.0147  0.032056      0.596309  0.058981  0.139670   \n",
      "1       0.2139   0.7696    0.0165  0.022058      0.541630  0.033564  0.135428   \n",
      "2       0.4252   0.5571    0.0178  0.027067      0.228047  0.020704  0.013944   \n",
      "3       0.0503   0.8259    0.1238  0.186106      0.097804  0.293471  0.611395   \n",
      "4       0.0956   0.8682    0.0362  0.069157      0.074829  0.156392  0.220893   \n",
      "...        ...      ...       ...       ...           ...       ...       ...   \n",
      "2739    0.0699   0.9200    0.0101  0.021431      0.145272  0.054925  0.100153   \n",
      "2740    0.1157   0.8048    0.0795  0.235763      0.172389  0.146248  0.028766   \n",
      "2741    0.0360   0.9129    0.0511  0.047253      0.303865  0.149934  0.159055   \n",
      "2742    0.0676   0.8960    0.0364  0.010760      0.397759  0.025006  0.121341   \n",
      "2743    0.0466   0.3480    0.6054  0.074261      0.221111  0.102754  0.085860   \n",
      "\n",
      "           joy      love  optimism  pessimism   sadness  surprise     trust  \\\n",
      "0     0.132072  0.008831  0.616930   0.095059  0.088055  0.044444  0.093437   \n",
      "1     0.152157  0.010925  0.683761   0.056417  0.043668  0.030434  0.113307   \n",
      "2     0.811792  0.026598  0.896001   0.012078  0.018877  0.017472  0.113543   \n",
      "3     0.008646  0.003616  0.175571   0.475258  0.685823  0.010338  0.016174   \n",
      "4     0.044991  0.004764  0.107376   0.211693  0.585573  0.010272  0.006690   \n",
      "...        ...       ...       ...        ...       ...       ...       ...   \n",
      "2739  0.253857  0.013910  0.564682   0.146528  0.526767  0.010223  0.024983   \n",
      "2740  0.177177  0.009510  0.907898   0.094388  0.166013  0.007790  0.089246   \n",
      "2741  0.105655  0.006099  0.160913   0.096040  0.254947  0.039387  0.015306   \n",
      "2742  0.168019  0.014589  0.651057   0.124955  0.232282  0.013428  0.063384   \n",
      "2743  0.060167  0.004255  0.504301   0.093535  0.124486  0.009615  0.027483   \n",
      "\n",
      "     Sentiment       Emotion  \n",
      "0      neutral      optimism  \n",
      "1      neutral      optimism  \n",
      "2      neutral      optimism  \n",
      "3      neutral       sadness  \n",
      "4      neutral       sadness  \n",
      "...        ...           ...  \n",
      "2739   neutral      optimism  \n",
      "2740   neutral      optimism  \n",
      "2741   neutral  anticipation  \n",
      "2742   neutral      optimism  \n",
      "2743       neg      optimism  \n",
      "\n",
      "[2744 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate \n",
    "result_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "total_length = sum(len(df) for df in dfs)\n",
    "assert len(result_df) == total_length, \"Length mismatch! Check!\"\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "result_df.to_csv(r\"C:\\Users\\alyas\\Desktop\\TER\\test_sentiment_analysis\\all_emo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1370044456842493954</td>\n",
       "      <td>Do fasting mimicking diets during chemotherapy...</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.032056</td>\n",
       "      <td>0.596309</td>\n",
       "      <td>0.058981</td>\n",
       "      <td>0.139670</td>\n",
       "      <td>0.132072</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.616930</td>\n",
       "      <td>0.095059</td>\n",
       "      <td>0.088055</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.093437</td>\n",
       "      <td>neutral</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>794281747043250176</td>\n",
       "      <td>#fasting may improve #cancer #treatment but ne...</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.7696</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>0.541630</td>\n",
       "      <td>0.033564</td>\n",
       "      <td>0.135428</td>\n",
       "      <td>0.152157</td>\n",
       "      <td>0.010925</td>\n",
       "      <td>0.683761</td>\n",
       "      <td>0.056417</td>\n",
       "      <td>0.043668</td>\n",
       "      <td>0.030434</td>\n",
       "      <td>0.113307</td>\n",
       "      <td>neutral</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1148806240010588161</td>\n",
       "      <td>Take notes.\\n\\nOrder your seamoss and receive ...</td>\n",
       "      <td>0.4252</td>\n",
       "      <td>0.5571</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.027067</td>\n",
       "      <td>0.228047</td>\n",
       "      <td>0.020704</td>\n",
       "      <td>0.013944</td>\n",
       "      <td>0.811792</td>\n",
       "      <td>0.026598</td>\n",
       "      <td>0.896001</td>\n",
       "      <td>0.012078</td>\n",
       "      <td>0.018877</td>\n",
       "      <td>0.017472</td>\n",
       "      <td>0.113543</td>\n",
       "      <td>neutral</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>643251385035657216</td>\n",
       "      <td>If you've ever been affected by #cancer #MUSTR...</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.8259</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.186106</td>\n",
       "      <td>0.097804</td>\n",
       "      <td>0.293471</td>\n",
       "      <td>0.611395</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>0.175571</td>\n",
       "      <td>0.475258</td>\n",
       "      <td>0.685823</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.016174</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1295469082221981696</td>\n",
       "      <td>The latest The STEM Daily! http #fasting #cancer</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.069157</td>\n",
       "      <td>0.074829</td>\n",
       "      <td>0.156392</td>\n",
       "      <td>0.220893</td>\n",
       "      <td>0.044991</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.107376</td>\n",
       "      <td>0.211693</td>\n",
       "      <td>0.585573</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>0.006690</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>91659659072647168</td>\n",
       "      <td>Cured: A Cannabis Story (A film by David Tripl...</td>\n",
       "      <td>0.0699</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.021431</td>\n",
       "      <td>0.145272</td>\n",
       "      <td>0.054925</td>\n",
       "      <td>0.100153</td>\n",
       "      <td>0.253857</td>\n",
       "      <td>0.013910</td>\n",
       "      <td>0.564682</td>\n",
       "      <td>0.146528</td>\n",
       "      <td>0.526767</td>\n",
       "      <td>0.010223</td>\n",
       "      <td>0.024983</td>\n",
       "      <td>neutral</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>98751766488813568</td>\n",
       "      <td>#Cannabis healing, the truth: http \"the govern...</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>0.8048</td>\n",
       "      <td>0.0795</td>\n",
       "      <td>0.235763</td>\n",
       "      <td>0.172389</td>\n",
       "      <td>0.146248</td>\n",
       "      <td>0.028766</td>\n",
       "      <td>0.177177</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>0.907898</td>\n",
       "      <td>0.094388</td>\n",
       "      <td>0.166013</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>0.089246</td>\n",
       "      <td>neutral</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>194423800673206272</td>\n",
       "      <td>Medical #marijuana bill passes committee - #Ca...</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>0.047253</td>\n",
       "      <td>0.303865</td>\n",
       "      <td>0.149934</td>\n",
       "      <td>0.159055</td>\n",
       "      <td>0.105655</td>\n",
       "      <td>0.006099</td>\n",
       "      <td>0.160913</td>\n",
       "      <td>0.096040</td>\n",
       "      <td>0.254947</td>\n",
       "      <td>0.039387</td>\n",
       "      <td>0.015306</td>\n",
       "      <td>neutral</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>197566368059637761</td>\n",
       "      <td>http If you have medical condition being treat...</td>\n",
       "      <td>0.0676</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.010760</td>\n",
       "      <td>0.397759</td>\n",
       "      <td>0.025006</td>\n",
       "      <td>0.121341</td>\n",
       "      <td>0.168019</td>\n",
       "      <td>0.014589</td>\n",
       "      <td>0.651057</td>\n",
       "      <td>0.124955</td>\n",
       "      <td>0.232282</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>0.063384</td>\n",
       "      <td>neutral</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>162632942022172673</td>\n",
       "      <td>Yo Christie! Don't be like Corzine! http #cann...</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.3480</td>\n",
       "      <td>0.6054</td>\n",
       "      <td>0.074261</td>\n",
       "      <td>0.221111</td>\n",
       "      <td>0.102754</td>\n",
       "      <td>0.085860</td>\n",
       "      <td>0.060167</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.504301</td>\n",
       "      <td>0.093535</td>\n",
       "      <td>0.124486</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.027483</td>\n",
       "      <td>neg</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2744 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               Text  \\\n",
       "0     1370044456842493954  Do fasting mimicking diets during chemotherapy...   \n",
       "1      794281747043250176  #fasting may improve #cancer #treatment but ne...   \n",
       "2     1148806240010588161  Take notes.\\n\\nOrder your seamoss and receive ...   \n",
       "3      643251385035657216  If you've ever been affected by #cancer #MUSTR...   \n",
       "4     1295469082221981696   The latest The STEM Daily! http #fasting #cancer   \n",
       "...                   ...                                                ...   \n",
       "2739    91659659072647168  Cured: A Cannabis Story (A film by David Tripl...   \n",
       "2740    98751766488813568  #Cannabis healing, the truth: http \"the govern...   \n",
       "2741   194423800673206272  Medical #marijuana bill passes committee - #Ca...   \n",
       "2742   197566368059637761  http If you have medical condition being treat...   \n",
       "2743   162632942022172673  Yo Christie! Don't be like Corzine! http #cann...   \n",
       "\n",
       "      positive  neutral  negative     anger  anticipation   disgust      fear  \\\n",
       "0       0.0687   0.9167    0.0147  0.032056      0.596309  0.058981  0.139670   \n",
       "1       0.2139   0.7696    0.0165  0.022058      0.541630  0.033564  0.135428   \n",
       "2       0.4252   0.5571    0.0178  0.027067      0.228047  0.020704  0.013944   \n",
       "3       0.0503   0.8259    0.1238  0.186106      0.097804  0.293471  0.611395   \n",
       "4       0.0956   0.8682    0.0362  0.069157      0.074829  0.156392  0.220893   \n",
       "...        ...      ...       ...       ...           ...       ...       ...   \n",
       "2739    0.0699   0.9200    0.0101  0.021431      0.145272  0.054925  0.100153   \n",
       "2740    0.1157   0.8048    0.0795  0.235763      0.172389  0.146248  0.028766   \n",
       "2741    0.0360   0.9129    0.0511  0.047253      0.303865  0.149934  0.159055   \n",
       "2742    0.0676   0.8960    0.0364  0.010760      0.397759  0.025006  0.121341   \n",
       "2743    0.0466   0.3480    0.6054  0.074261      0.221111  0.102754  0.085860   \n",
       "\n",
       "           joy      love  optimism  pessimism   sadness  surprise     trust  \\\n",
       "0     0.132072  0.008831  0.616930   0.095059  0.088055  0.044444  0.093437   \n",
       "1     0.152157  0.010925  0.683761   0.056417  0.043668  0.030434  0.113307   \n",
       "2     0.811792  0.026598  0.896001   0.012078  0.018877  0.017472  0.113543   \n",
       "3     0.008646  0.003616  0.175571   0.475258  0.685823  0.010338  0.016174   \n",
       "4     0.044991  0.004764  0.107376   0.211693  0.585573  0.010272  0.006690   \n",
       "...        ...       ...       ...        ...       ...       ...       ...   \n",
       "2739  0.253857  0.013910  0.564682   0.146528  0.526767  0.010223  0.024983   \n",
       "2740  0.177177  0.009510  0.907898   0.094388  0.166013  0.007790  0.089246   \n",
       "2741  0.105655  0.006099  0.160913   0.096040  0.254947  0.039387  0.015306   \n",
       "2742  0.168019  0.014589  0.651057   0.124955  0.232282  0.013428  0.063384   \n",
       "2743  0.060167  0.004255  0.504301   0.093535  0.124486  0.009615  0.027483   \n",
       "\n",
       "     Sentiment       Emotion  \n",
       "0      neutral      optimism  \n",
       "1      neutral      optimism  \n",
       "2      neutral      optimism  \n",
       "3      neutral       sadness  \n",
       "4      neutral       sadness  \n",
       "...        ...           ...  \n",
       "2739   neutral      optimism  \n",
       "2740   neutral      optimism  \n",
       "2741   neutral  anticipation  \n",
       "2742   neutral      optimism  \n",
       "2743       neg      optimism  \n",
       "\n",
       "[2744 rows x 18 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = pd.read_csv(r'C:\\Users\\alyas\\Desktop\\TER\\test_sentiment_analysis\\all_emo.csv', sep=\",\")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the model and tokenizer\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcardiffnlp/twitter-roberta-base-emotion-multilabel-latest\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Get the list of emotion labels from the model's configuration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alyas\\miniconda3\\envs\\emotions\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:423\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_auto\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m--> 423\u001b[0m     config, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[1;32mc:\\Users\\alyas\\miniconda3\\envs\\emotions\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:746\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m    745\u001b[0m     config_class \u001b[38;5;241m=\u001b[39m CONFIG_MAPPING[config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m--> 746\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconfig_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;66;03m# Fallback: use pattern matching on the string.\u001b[39;00m\n\u001b[0;32m    749\u001b[0m     \u001b[38;5;66;03m# We go from longer names to shorter names to catch roberta before bert (for instance)\u001b[39;00m\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(CONFIG_MAPPING\u001b[38;5;241m.\u001b[39mkeys(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\alyas\\miniconda3\\envs\\emotions\\lib\\site-packages\\transformers\\configuration_utils.py:706\u001b[0m, in \u001b[0;36mPretrainedConfig.from_dict\u001b[1;34m(cls, config_dict, **kwargs)\u001b[0m\n\u001b[0;32m    703\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_auto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    704\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 706\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpruned_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    709\u001b[0m     config\u001b[38;5;241m.\u001b[39mpruned_heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((\u001b[38;5;28mint\u001b[39m(key), value) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mpruned_heads\u001b[38;5;241m.\u001b[39mitems())\n",
      "File \u001b[1;32mc:\\Users\\alyas\\miniconda3\\envs\\emotions\\lib\\site-packages\\transformers\\models\\roberta\\configuration_roberta.py:68\u001b[0m, in \u001b[0;36mRobertaConfig.__init__\u001b[1;34m(self, pad_token_id, bos_token_id, eos_token_id, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pad_token_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, bos_token_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, eos_token_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs RobertaConfig.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbos_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alyas\\miniconda3\\envs\\emotions\\lib\\site-packages\\transformers\\models\\bert\\configuration_bert.py:159\u001b[0m, in \u001b[0;36mBertConfig.__init__\u001b[1;34m(self, vocab_size, hidden_size, num_hidden_layers, num_attention_heads, intermediate_size, hidden_act, hidden_dropout_prob, attention_probs_dropout_prob, max_position_embeddings, type_vocab_size, initializer_range, layer_norm_eps, pad_token_id, position_embedding_type, use_cache, classifier_dropout, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    141\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30522\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    158\u001b[0m ):\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m vocab_size\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size \u001b[38;5;241m=\u001b[39m hidden_size\n",
      "File \u001b[1;32mc:\\Users\\alyas\\miniconda3\\envs\\emotions\\lib\\site-packages\\transformers\\configuration_utils.py:327\u001b[0m, in \u001b[0;36mPretrainedConfig.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtorch_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtorch_dtype, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;66;03m# we will start using self.torch_dtype in v5, but to be consistent with\u001b[39;00m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;66;03m# from_pretrained's torch_dtype arg convert it to an actual torch.dtype object\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 327\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtorch_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtorch_dtype)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# Tokenizer arguments TODO: eventually tokenizer and models should share the same config\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alyas\\miniconda3\\envs\\emotions\\lib\\site-packages\\torch\\__init__.py:123\u001b[0m\n\u001b[0;32m    121\u001b[0m is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_load_library_flags:\n\u001b[1;32m--> 123\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mkernel32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadLibraryExW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0x00001100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     last_error \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mget_last_error()\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m last_error \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m126\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-emotion-multilabel-latest\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Get the list of emotion labels from the model's configuration\n",
    "labels = model.config.id2label\n",
    "\n",
    "# Create a function to get emotion labels with all scores\n",
    "def get_emotion_labels(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    scores = logits.sigmoid().tolist()[0]\n",
    "    return [{\"label\": labels[i], \"score\": score} for i, score in enumerate(scores)]\n",
    "\n",
    "# Use the function to get emotion labels with all scores\n",
    "result = get_emotion_labels(\"I bet everything will work out in the end :)\")\n",
    "print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
